{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dd326b-2fed-48e4-a61f-e3aa25ab6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impleneting a hands-free mouse control system using computer vision and facial\n",
    "#landmark detection by using OpenCV, MediaPipe FaceMesh, and PyAutoGUI. The system enables users to move the mouse\n",
    "#cursor using eye movement and perform clicks through blinking. Please use your left eye to click."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "476e1cb3-3a91-46b8-8505-2d8f6a7b5fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2  # OpenCV for capturing and processing video\n",
    "import mediapipe as mp  # MediaPipe for facial landmark detection\n",
    "import pyautogui  # PyAutoGUI for controlling the mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1870db7-da5d-4caa-bd09-a2d792263632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize webcam\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize MediaPipe FaceMesh model with refined landmarks for more accuracy\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)\n",
    "\n",
    "# Get the screen width and height for mapping eye movement to the screen\n",
    "screen_w, screen_h = pyautogui.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e8109d-a07d-4b1f-88bd-989e23e514e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infinite loop to continuously process video frames\n",
    "while True:\n",
    "    # Read a frame from the webcam\n",
    "    _, frame = cam.read()\n",
    "    \n",
    "    # Flip the frame horizontally to act as a mirror\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Convert frame from BGR (OpenCV default) to RGB (MediaPipe requires RGB)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the frame using the FaceMesh model to detect facial landmarks\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    \n",
    "    # Get detected face landmarks\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    \n",
    "    # Get frame dimensions\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "\n",
    "    # If facial landmarks are detected\n",
    "    if landmark_points:\n",
    "        # Extract the first detected face's landmarks\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        \n",
    "        # Iterate through specific landmarks (474-478), which are around the eyes\n",
    "        for id, landmark in enumerate(landmarks[474:478]):\n",
    "            # Convert normalized landmark coordinates to pixel values\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            \n",
    "            # Draw a small green circle around the detected eye landmarks\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            \n",
    "            # Use one specific landmark (id == 1) to control mouse movement\n",
    "            if id == 1:\n",
    "                # Map facial landmark coordinates to screen coordinates\n",
    "                screen_x = screen_w * landmark.x\n",
    "                screen_y = screen_h * landmark.y\n",
    "                \n",
    "                # Move the mouse cursor to the calculated screen coordinates\n",
    "                pyautogui.moveTo(screen_x, screen_y)\n",
    "\n",
    "        # Select two specific landmarks for eye blinking detection (145 and 159)\n",
    "        left = [landmarks[145], landmarks[159]]\n",
    "\n",
    "        # Draw circles on these landmarks for visualization\n",
    "        for landmark in left:\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 255))  # Yellow color\n",
    "\n",
    "        # Detect blink based on vertical eye distance threshold\n",
    "        if (left[0].y - left[1].y) < 0.004:\n",
    "            # Perform a mouse click if blink is detected\n",
    "            pyautogui.click()\n",
    "            # Add a small delay to prevent multiple clicks from a single blink\n",
    "            pyautogui.sleep(1)\n",
    "\n",
    "    # Display the video feed with annotations\n",
    "    cv2.imshow('Eye Controlled Mouse', frame)\n",
    "    \n",
    "    # Wait for a key press for 1ms (non-blocking)\n",
    "    cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
